# With NCCL channel, remove --colocate_critic_reward, --fp16,  --flash_attn
python3 -m openrlhf.cli.train_ppo_ray    --ref_num_nodes 1    --ref_num_gpus_per_node 1    --reward_num_nodes 1    --reward_num_gpus_per_node 1    --critic_num_nodes 1    --critic_num_gpus_per_node 1    --actor_num_nodes 1    --actor_num_gpus_per_node 1    --vllm_num_engines 1    --vllm_tensor_parallel_size 1        --colocate_actor_ref    --pretrain SumanthRH/OpenRLHF-smol-sft-mixture    --reward_pretrain SumanthRH/OpenRLHF-smol-rm-mixture    --save_path /openrlhf/examples/checkpoint/llama3-8b-rlhf    --micro_train_batch_size 1    --train_batch_size 4    --micro_rollout_batch_size 2    --rollout_batch_size 8    --max_samples 100000    --max_epochs 1    --prompt_max_len 256    --generate_max_len 256    --zero_stage 3      --actor_learning_rate 5e-7    --critic_learning_rate 9e-6    --init_kl_coef 0.01    --prompt_data OpenRLHF/prompt-collection-v0.1    --input_key context_messages    --apply_chat_template    --normalize_reward    --adam_offload    